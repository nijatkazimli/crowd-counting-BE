{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "jXyPBEPIAad7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('/content/drive/MyDrive/model/640_50/best.pt')\n",
        "\n",
        "test_images_path = '/content/drive/MyDrive/dataset/640/test/images'\n",
        "test_labels_path = '/content/drive/MyDrive/dataset/640/test/labels'"
      ],
      "metadata": {
        "id": "ViiEqtPABGJH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 1: Check if the model loads correctly\n",
        "def test_model_loading(model_path):\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "        print(\"✅ Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Model loading failed: {e}\")\n",
        "\n",
        "test_model_loading('/content/drive/MyDrive/model/640_50/best.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ssPXkVlAmpB",
        "outputId": "1f6ac815-2bad-4125-ebb7-d1a150fb7e76"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2: Verify prediction output structure\n",
        "def test_prediction_output(model, test_images_path):\n",
        "    try:\n",
        "        test_image = os.listdir(test_images_path)[0]\n",
        "        image_path = os.path.join(test_images_path, test_image)\n",
        "        image = cv2.imread(image_path)\n",
        "        results = model.predict(image)\n",
        "\n",
        "        assert hasattr(results[0], 'boxes'), \"Prediction output lacks 'boxes'.\"\n",
        "        print(\"✅ Prediction output structure is valid.\")\n",
        "    except AssertionError as e:\n",
        "        print(f\"❌ {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during prediction: {e}\")\n",
        "\n",
        "test_prediction_output(model, test_images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE5C_9hOBNwR",
        "outputId": "3c5337ae-05f9-4e7b-d3f2-0437f8a24d8a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 9 persons, 308.7ms\n",
            "Speed: 5.3ms preprocess, 308.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "✅ Prediction output structure is valid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 3: Check if the model handles batch predictions\n",
        "def test_batch_prediction(model, test_images_path):\n",
        "    try:\n",
        "        image_files = os.listdir(test_images_path)[:5]  # Test with 5 images\n",
        "        images = [cv2.imread(os.path.join(test_images_path, img)) for img in image_files]\n",
        "        results = model.predict(images)\n",
        "\n",
        "        assert len(results) == 5, \"Batch prediction results do not match input batch size.\"\n",
        "        print(\"✅ Batch prediction works as expected.\")\n",
        "    except AssertionError as e:\n",
        "        print(f\"❌ {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during batch prediction: {e}\")\n",
        "\n",
        "test_batch_prediction(model, test_images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BafhVjkVBTvG",
        "outputId": "dff0b7dd-826c-4c72-aa45-7b172f4a7e9a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 9 persons, 214.0ms\n",
            "1: 640x640 20 persons, 214.0ms\n",
            "2: 640x640 27 persons, 214.0ms\n",
            "3: 640x640 9 persons, 214.0ms\n",
            "4: 640x640 5 persons, 214.0ms\n",
            "Speed: 3.6ms preprocess, 214.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "✅ Batch prediction works as expected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 4: Validate prediction counts (non-negative output)\n",
        "def test_prediction_counts(model, test_images_path):\n",
        "    try:\n",
        "        test_image = os.listdir(test_images_path)[0]\n",
        "        image_path = os.path.join(test_images_path, test_image)\n",
        "        image = cv2.imread(image_path)\n",
        "        results = model.predict(image)\n",
        "        count = len(results[0].boxes)\n",
        "\n",
        "        assert count >= 0, \"Prediction count should be non-negative.\"\n",
        "        print(f\"✅ Prediction count is valid: {count}.\")\n",
        "    except AssertionError as e:\n",
        "        print(f\"❌ {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during count validation: {e}\")\n",
        "\n",
        "test_prediction_counts(model, test_images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgTuV5VBBrMY",
        "outputId": "30254abe-094a-498e-8d5a-10aa15e49055"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 9 persons, 193.7ms\n",
            "Speed: 3.4ms preprocess, 193.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "✅ Prediction count is valid: 9.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 5: Test model inference time\n",
        "def test_inference_time(model, test_images_path):\n",
        "    import time\n",
        "    try:\n",
        "        test_image = os.listdir(test_images_path)[0]\n",
        "        image_path = os.path.join(test_images_path, test_image)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        start_time = time.time()\n",
        "        model.predict(image)\n",
        "        end_time = time.time()\n",
        "\n",
        "        inference_time = end_time - start_time\n",
        "        print(f\"✅ Model inference time: {inference_time:.2f} seconds.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during inference timing: {e}\")\n",
        "\n",
        "test_inference_time(model, test_images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-XRzAssB0jO",
        "outputId": "97b69cec-7b22-48a9-8a89-46b002f9781f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 9 persons, 199.4ms\n",
            "Speed: 3.3ms preprocess, 199.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "✅ Model inference time: 0.21 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 6: Handle non-image input gracefully\n",
        "def test_non_image_input(model):\n",
        "    try:\n",
        "        dummy_input = np.random.random((224, 224, 3))\n",
        "        model.predict(dummy_input)\n",
        "        print(\"✅ Model handled non-image input without crashing.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Model failed on non-image input: {e}\")\n",
        "\n",
        "test_non_image_input(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03tZlU8lB1va",
        "outputId": "7126b47a-96cc-47a8-c8f1-f340d56936c5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 (no detections), 208.7ms\n",
            "Speed: 12.4ms preprocess, 208.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "✅ Model handled non-image input without crashing.\n"
          ]
        }
      ]
    }
  ]
}